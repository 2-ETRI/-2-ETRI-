{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92301a18",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7d8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "import math\n",
    "warnings.filterwarnings(action='ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.read_csv('./complete_data(2020 추가).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05c20c",
   "metadata": {},
   "source": [
    "# 피처정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39774a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action 데이터의 결측은 모두 0으로 생각합니다.\n",
    "for col in df.columns:\n",
    "    if col.startswith('action'):\n",
    "        df[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b638e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1과 2를 0, 3은 1, 4와 5는 2로 바꿔줍니다.\n",
    "for var in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "    df[var] = df[var].map({1:0, 2:0, 3:1, 4:2, 5:2})\n",
    "\n",
    "# 0은 0, 나머지는 1로 바꿔줍니다.\n",
    "df[\"('Post_sleepProblem',)\"] = df[\"('Post_sleepProblem',)\"].map({0:0, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1})\n",
    "\n",
    "# 4는 0, 나머지는 1로 바꿔줍니다.\n",
    "df[\"('Post_dream',)\"] = df[\"('Post_dream',)\"].map({4:0, 1:1, 2:1, 3:1})\n",
    "\n",
    "# 1과 2를 0, 3은 1, 4와 5는 2로 바꿔줍니다.\n",
    "for var in [\"sleep\", \"amCondition\", \"amEmotion\"]:\n",
    "    df[var] = df[var].map({1:0, 2:0, 3:1, 4:2, 5:2})\n",
    "\n",
    "# 0은 0, 나머지는 1로 바꿔줍니다.\n",
    "df[\"sleepProblem\"] = df[\"sleepProblem\"].map({0:0, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1})\n",
    "\n",
    "# \"('Post_dream',)\"은 4는 0, 나머지는 1로 바꿔줍니다.\n",
    "df[\"dream\"] = df[\"dream\"].map({4:0, 1:1, 2:1, 3:1})\n",
    "\n",
    "# 1과 2를 0, 3은 1, 4와 5는 2로 바꿔줍니다.\n",
    "for var in [\"pmEmotion\", \"pmStress\", \"pmFatigue\"]:\n",
    "    df[var] = df[var].map({1:0, 2:0, 3:1, 4:2, 5:2})\n",
    "\n",
    "# bmi 피처를 생성합니다.\n",
    "df['bmi'] = df['weight'] / (df['height']/100)**2\n",
    "df.drop(columns=['height', 'weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10de9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비슷한 의미를 가진 피처를 통합합니다.\n",
    "df['action_recreation_media'] = df['action_recreation_media'] + df['action_entertainment'] + df['action_hobby'] + df['action_recreation_etc']\n",
    "df.drop(columns=['action_entertainment', 'action_hobby', 'action_recreation_etc'], inplace=True)\n",
    "\n",
    "df['action_community_interaction'] = df['action_community_interaction'] + df['action_socialising']\n",
    "df.drop(columns=['action_socialising'], inplace=True)\n",
    "\n",
    "df['place_other_indoor'] = df['place_other_indoor'] + df['place_restaurant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96924736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 큰 범주 데이터만 포함시키고 Sub는 제거합니다.\n",
    "df.drop(columns=['actionOption_751', 'actionOption_793', 'actionSubOption_1',\n",
    "       'actionSubOption_2', 'actionSubOption_3', 'actionSubOption_4',\n",
    "       'actionSubOption_5', 'conditionSub1Option_1', 'conditionSub1Option_2',\n",
    "       'conditionSub1Option_3', 'conditionSub1Option_4',\n",
    "       'conditionSub1Option_5'], inplace=True)\n",
    "\n",
    "df.drop(columns=['activity_3', 'activity_4', 'activity_5', 'activity_7', 'activity_8'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaad7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜가 주기성을 가지도록 변경합니다.\n",
    "\n",
    "# date 칼럼을 datetime 형식으로 변환합니다.\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df[\"('Pre_startDt',)\"] = pd.to_datetime(df[\"('Pre_startDt',)\"])\n",
    "df[\"('Pre_endDt',)\"] = pd.to_datetime(df[\"('Pre_endDt',)\"])\n",
    "\n",
    "# month 칼럼에 달 정보를 저장합니다.\n",
    "df['month'] = df['date'].apply(lambda x: x.month)\n",
    "\n",
    "start_time = df[\"('Pre_startDt',)\"].dt.hour\n",
    "start_time = df[\"('Pre_startDt',)\"].dt.minute\n",
    "end_time = df[\"('Pre_endDt',)\"].dt.hour\n",
    "end_time = df[\"('Pre_endDt',)\"].dt.minute\n",
    "\n",
    "for i in range(len(start_time)):\n",
    "    if pd.notnull(start_time[i]):\n",
    "        hour = start_time[i]\n",
    "        minute = start_time[i]\n",
    "\n",
    "        # 30분 이상이면 1시간 추가, 30분 미만이면 버림\n",
    "        if minute >= 30:\n",
    "            hour += 1\n",
    "        else:\n",
    "            minute = 0\n",
    "\n",
    "        # 시간 값이 24 이상이면 24를 뺀 나머지 값으로 변경\n",
    "        hour = hour % 24\n",
    "\n",
    "        # datetime 객체로 변환하여 저장\n",
    "        start_time[i] = hour\n",
    "\n",
    "    if pd.notnull(end_time[i]):\n",
    "        hour = end_time[i]\n",
    "        minute = end_time[i]\n",
    "\n",
    "        # 30분 이상이면 1시간 추가, 30분 미만이면 버림\n",
    "        if minute >= 30:\n",
    "            hour += 1\n",
    "        else:\n",
    "            minute = 0\n",
    "\n",
    "        # 시간 값이 24 이상이면 24를 뺀 나머지 값으로 변경\n",
    "        hour = hour % 24\n",
    "\n",
    "        # datetime \n",
    "        end_time[i] = hour\n",
    "        \n",
    "# sin, cos 변환\n",
    "start_sin = np.sin(2 * np.pi * start_time / 24)\n",
    "start_cos = np.cos(2 * np.pi * start_time / 24)\n",
    "\n",
    "end_sin = np.sin(2 * np.pi * end_time / 24)\n",
    "end_cos = np.cos(2 * np.pi * end_time / 24)\n",
    "\n",
    "df['pre_start_sin']  = start_sin\n",
    "df['pre_start_cos']  = start_cos\n",
    "\n",
    "df['pre_end_sin']  = end_sin\n",
    "df['pre_end_cos']  = end_cos\n",
    "\n",
    "# sin, cos 변환\n",
    "month_sin = np.sin(2 * np.pi * start_time / 24)\n",
    "month_cos = np.cos(2 * np.pi * start_time / 24)\n",
    "\n",
    "df['month_sin']  = month_sin\n",
    "df['month_cos']  = month_cos\n",
    "\n",
    "df = df.drop(columns=[\"('Pre_startDt',)\", \"('Pre_endDt',)\", 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88c1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 형식을 맞춥니다.\n",
    "df.loc[df['gender'] == 'F', 'gender'] = 0\n",
    "df.loc[df['gender'] == 'M', 'gender'] = 1\n",
    "df['gender'] = df['gender'].astype(float)\n",
    "df['age'] = df['age'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670273e",
   "metadata": {},
   "source": [
    "# 데이터셋을 나눕니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4018954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 데이터가 결측인 경우는 제거합니다.\n",
    "target = [\"('Post_sleep',)\", \"('Post_sleepProblem',)\", \"('Post_dream',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]\n",
    "\n",
    "df.dropna(subset=target, inplace=True)\n",
    "df.drop_duplicates(keep='last', inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fbdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 피처를 선별하고, target을 정합니다.\n",
    "now_common = ['userId', 'gender', 'age', 'action_personal_care', 'action_sleep',\n",
    "          'action_work', 'action_study', 'action_household', 'action_recreation_media',\n",
    "          'action_outdoor_act','action_community_interaction', 'action_travel', 'action_meal',\n",
    "          'place_home', 'place_workplace', 'place_outdoor', 'place_other_indoor', 'avg_emotionPositive',\n",
    "          'avg_emotionTension', 'activity_0', 'activity_1', 'activity_2', 'pre_start_sin', 'pre_start_cos', 'pre_end_sin', 'pre_end_cos', 'sleep', 'sleepProblem', \n",
    "          'dream', 'amCondition', 'amEmotion', 'pmEmotion', 'pmStress', 'alcohol', 'caffeine', 'condition_ALONE', 'condition_NOT_ALONE', \"('Pre_wakeupcount',)\"]\n",
    "now_2018_2019 = ['action_communitiy_interaction', \"('Pre_total_sleep_time',)\", \"('Pre_time_in_bed',)\", \"('Pre_waso',)\", \"('Pre_aal',)\", \"('Pre_movement_index',)\", \"('Pre_fragmentation_index',)\", \"('Pre_sleep_frag_index',)\"]\n",
    "now_2020 = ['bmi', 'action_care_housemem', 'action_shop', \"('Pre_wakeupduration',)\", \"('Pre_lightsleepduration',)\", \"('Pre_deepsleepduration',)\", \"('Pre_durationtosleep',)\", \"('Pre_remsleepduration',)\", \"('Pre_durationtowakeup',)\", \"('Pre_hr_average',)\", \"('Pre_hr_min',)\", \"('Pre_hr_max',)\", \"('Pre_rr_average',)\", \"('Pre_rr_min',)\", \"('Pre_rr_max',)\", \"('Pre_breathing_disturbances_intensity',)\", \"('Pre_snoring',)\", \"('Pre_snoringepisodecount',)\", 'pmFatigue']\n",
    "\n",
    "next_common = [\"('Post_sleep',)\", \"('Post_sleepProblem',)\", \"('Post_dream',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]\n",
    "\n",
    "df = df[now_common + now_2018_2019 + now_2020 + next_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c23bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 2018, 2019, 2020으로 분리합니다.\n",
    "df2018_2019 = df[df['userId'].str.startswith('2018')]\n",
    "df2018 = df2018_2019[df2018_2019['userId'].str.contains(\"[a-zA-Z]{3}\\d{3}$\")]\n",
    "df2018.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df2019 = df2018_2019[~df2018_2019['userId'].str.contains(\"[a-zA-Z]{3}\\d{3}$\")]\n",
    "df2019.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df2020 = df[df['userId'].str.startswith('2020')]\n",
    "df2020.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# 향후 사용을 위해 참여 년도를 피처로 추가해둡니다.\n",
    "df['pat_year_2018'] = [1] * len(df2018) + [0] * len(df2019) + [0] * len(df2020)\n",
    "df['pat_year_2019'] = [0] * len(df2018) + [1] * len(df2019) + [0] * len(df2020)\n",
    "df['pat_year_2020'] = [0] * len(df2018) + [0] * len(df2019) + [1] * len(df2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd173a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋을 저장해둡니다.\n",
    "total_df = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6319fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 피처와 수치형 피처를 구분합니다.\n",
    "category = ['gender', 'sleep', 'sleepProblem', 'dream', 'amCondition', 'amEmotion', 'pmEmotion', 'pmStress', 'alcohol', 'caffeine', 'pmFatigue']\n",
    "numeric = ['age', 'action_personal_care',\n",
    "           'action_sleep', 'action_communitiy_interaction', 'action_work',\n",
    "           'action_study', 'action_household', 'action_recreation_media',\n",
    "           'action_care_housemem', 'action_shop', 'action_outdoor_act',\n",
    "           'action_community_interaction', 'action_travel', 'action_meal',\n",
    "           'place_home', 'place_workplace', 'place_outdoor', 'place_other_indoor',\n",
    "           'avg_emotionPositive', 'avg_emotionTension', 'activity_0', 'activity_1',\n",
    "           'activity_2', 'condition_ALONE', 'condition_NOT_ALONE', 'bmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317754ae",
   "metadata": {},
   "source": [
    "# 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82f024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b34d0553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    633\n",
       "1.0    378\n",
       "0.0    329\n",
       "Name: sleep, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sleep'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b6855a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    720\n",
       "1.0    620\n",
       "Name: sleepProblem, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sleepProblem\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f701520d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    832\n",
       "1.0    508\n",
       "Name: dream, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dream\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d43666e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    633\n",
       "2.0    361\n",
       "1.0    346\n",
       "Name: amCondition, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"amCondition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "536e0b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    619\n",
       "2.0    406\n",
       "0.0    315\n",
       "Name: amEmotion, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"amEmotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac532e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1340 entries, 0 to 1339\n",
      "Data columns (total 73 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   userId                                     1340 non-null   object \n",
      " 1   gender                                     1340 non-null   float64\n",
      " 2   age                                        1340 non-null   float64\n",
      " 3   action_personal_care                       1340 non-null   float64\n",
      " 4   action_sleep                               1340 non-null   float64\n",
      " 5   action_work                                1340 non-null   float64\n",
      " 6   action_study                               1340 non-null   float64\n",
      " 7   action_household                           1340 non-null   float64\n",
      " 8   action_recreation_media                    1340 non-null   float64\n",
      " 9   action_outdoor_act                         1340 non-null   float64\n",
      " 10  action_community_interaction               1340 non-null   float64\n",
      " 11  action_travel                              1340 non-null   float64\n",
      " 12  action_meal                                1340 non-null   float64\n",
      " 13  place_home                                 1271 non-null   float64\n",
      " 14  place_workplace                            1271 non-null   float64\n",
      " 15  place_outdoor                              1271 non-null   float64\n",
      " 16  place_other_indoor                         1271 non-null   float64\n",
      " 17  avg_emotionPositive                        1271 non-null   float64\n",
      " 18  avg_emotionTension                         1271 non-null   float64\n",
      " 19  activity_0                                 1271 non-null   float64\n",
      " 20  activity_1                                 1271 non-null   float64\n",
      " 21  activity_2                                 1271 non-null   float64\n",
      " 22  pre_start_sin                              971 non-null    float64\n",
      " 23  pre_start_cos                              971 non-null    float64\n",
      " 24  pre_end_sin                                971 non-null    float64\n",
      " 25  pre_end_cos                                971 non-null    float64\n",
      " 26  sleep                                      1340 non-null   float64\n",
      " 27  sleepProblem                               1340 non-null   float64\n",
      " 28  dream                                      1340 non-null   float64\n",
      " 29  amCondition                                1340 non-null   float64\n",
      " 30  amEmotion                                  1340 non-null   float64\n",
      " 31  pmEmotion                                  1239 non-null   float64\n",
      " 32  pmStress                                   1239 non-null   float64\n",
      " 33  alcohol                                    1340 non-null   float64\n",
      " 34  caffeine                                   1340 non-null   float64\n",
      " 35  condition_ALONE                            1271 non-null   float64\n",
      " 36  condition_NOT_ALONE                        1271 non-null   float64\n",
      " 37  ('Pre_wakeupcount',)                       771 non-null    float64\n",
      " 38  action_communitiy_interaction              1340 non-null   float64\n",
      " 39  ('Pre_total_sleep_time',)                  459 non-null    float64\n",
      " 40  ('Pre_time_in_bed',)                       459 non-null    float64\n",
      " 41  ('Pre_waso',)                              259 non-null    float64\n",
      " 42  ('Pre_aal',)                               259 non-null    float64\n",
      " 43  ('Pre_movement_index',)                    259 non-null    float64\n",
      " 44  ('Pre_fragmentation_index',)               259 non-null    float64\n",
      " 45  ('Pre_sleep_frag_index',)                  259 non-null    float64\n",
      " 46  bmi                                        1037 non-null   float64\n",
      " 47  action_care_housemem                       1340 non-null   float64\n",
      " 48  action_shop                                1340 non-null   float64\n",
      " 49  ('Pre_wakeupduration',)                    512 non-null    float64\n",
      " 50  ('Pre_lightsleepduration',)                512 non-null    float64\n",
      " 51  ('Pre_deepsleepduration',)                 512 non-null    float64\n",
      " 52  ('Pre_durationtosleep',)                   512 non-null    float64\n",
      " 53  ('Pre_remsleepduration',)                  512 non-null    float64\n",
      " 54  ('Pre_durationtowakeup',)                  512 non-null    float64\n",
      " 55  ('Pre_hr_average',)                        512 non-null    float64\n",
      " 56  ('Pre_hr_min',)                            512 non-null    float64\n",
      " 57  ('Pre_hr_max',)                            512 non-null    float64\n",
      " 58  ('Pre_rr_average',)                        512 non-null    float64\n",
      " 59  ('Pre_rr_min',)                            512 non-null    float64\n",
      " 60  ('Pre_rr_max',)                            512 non-null    float64\n",
      " 61  ('Pre_breathing_disturbances_intensity',)  512 non-null    float64\n",
      " 62  ('Pre_snoring',)                           512 non-null    float64\n",
      " 63  ('Pre_snoringepisodecount',)               512 non-null    float64\n",
      " 64  pmFatigue                                  629 non-null    float64\n",
      " 65  ('Post_sleep',)                            1340 non-null   float64\n",
      " 66  ('Post_sleepProblem',)                     1340 non-null   float64\n",
      " 67  ('Post_dream',)                            1340 non-null   float64\n",
      " 68  ('Post_amCondition',)                      1340 non-null   float64\n",
      " 69  ('Post_amEmotion',)                        1340 non-null   float64\n",
      " 70  pat_year_2018                              1340 non-null   int64  \n",
      " 71  pat_year_2019                              1340 non-null   int64  \n",
      " 72  pat_year_2020                              1340 non-null   int64  \n",
      "dtypes: float64(69), int64(3), object(1)\n",
      "memory usage: 764.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ca3b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "# category 데이터에서는 최빈값(mode)으로 대체합니다.\n",
    "for col in category:\n",
    "    try:\n",
    "        df2018[col].fillna(df2018[col].mode()[0], inplace=True)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df2018_imputed = mice_imputer.fit_transform(df2018.drop(columns=['userId']).values)\n",
    "df2018_imputed = pd.DataFrame(df2018_imputed, columns=df2018.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec8ed502",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "# category 데이터에서는 최빈값(mode)으로 대체합니다.\n",
    "for col in category:\n",
    "    try:\n",
    "        df2019[col].fillna(df2019[col].mode()[0], inplace=True)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df2019_imputed = mice_imputer.fit_transform(df2019.drop(columns=['userId']).values)\n",
    "df2019_imputed = pd.DataFrame(df2019_imputed, columns=df2019.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940339ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "# category 데이터에서는 최빈값(mode)으로 대체합니다.\n",
    "for col in category:\n",
    "    try:\n",
    "        df2020[col].fillna(df2020[col].mode()[0], inplace=True)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df2020_imputed = mice_imputer.fit_transform(df2020.drop(columns=['userId']).values)\n",
    "df2020_imputed = pd.DataFrame(df2020_imputed, columns=df2020.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3746ed",
   "metadata": {},
   "source": [
    "# 단순통합(최대)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "962a0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 균일하게 나누기 위해 year 컬럼을 생성합니다.\n",
    "year = []\n",
    "for id in total_df['userId']:\n",
    "    if id in df2018['userId'].unique(): year.append('2018')\n",
    "    elif id in df2019['userId'].unique(): year.append('2019')\n",
    "    elif id in df2020['userId'].unique(): year.append('2020')\n",
    "total_df['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1c64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    global IterativeImputer\n",
    "    global result_df\n",
    "    \n",
    "    # 데이터 준비\n",
    "    user_ids = total_df[\"userId\"].unique()\n",
    "    user_years = total_df.groupby('userId')['year'].first()\n",
    "\n",
    "\n",
    "    train_user_ids, test_user_ids = train_test_split(user_ids, test_size=0.2, random_state=x, stratify=user_years)\n",
    "    train_total = total_df[total_df[\"userId\"].isin(train_user_ids)]\n",
    "    test_total = total_df[total_df[\"userId\"].isin(test_user_ids)]\n",
    "    \n",
    "    train_total.drop(columns=['userId', 'year'], inplace=True)\n",
    "    year = test_total['year'].reset_index(drop=True)\n",
    "    test_total.drop(columns=['userId', 'year'], inplace=True)\n",
    "\n",
    "    # 범주형 변수는 먼저 최빈값으로 결측치를 대체합니다.\n",
    "    for col in category:\n",
    "        try:\n",
    "            train_total[col].fillna(train_total[col].mode()[0], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    for col in category:\n",
    "        try:\n",
    "            test_total[col].fillna(train_total[col].mode()[0], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Mice 모델로 결측치를 대체합니다.\n",
    "    mice_imputer = IterativeImputer()\n",
    "    try:\n",
    "        train_total_imputed = mice_imputer.fit_transform(train_total.values)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    train_total_imputed = pd.DataFrame(train_total_imputed, columns=train_total.columns)\n",
    "    train_total_imputed = train_total_imputed.where(train_total_imputed >= train_total.min(), train_total.min(), axis=1)\n",
    "    train_total_imputed = train_total_imputed.where(train_total_imputed <= train_total.max(), train_total.max(), axis=1)\n",
    "\n",
    "    try:\n",
    "        test_total_imputed = mice_imputer.transform(test_total.values)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    test_total_imputed = pd.DataFrame(test_total_imputed, columns=test_total.columns)\n",
    "    test_total_imputed = test_total_imputed.where(test_total_imputed >= train_total.min(), train_total.min(), axis=1)\n",
    "    test_total_imputed = test_total_imputed.where(test_total_imputed <= train_total.max(), train_total.max(), axis=1)\n",
    "    \n",
    "    # target과 numeric_cols를 구분하여 사용 피처를 확정합니다.\n",
    "    target = [\"('Post_sleep',)\", \"('Post_sleepProblem',)\", \"('Post_dream',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]\n",
    "    numeric_cols = ['age', 'action_personal_care', 'action_sleep',\n",
    "           'action_work', 'action_study', 'action_household',\n",
    "           'action_recreation_media', 'action_care_housemem', 'action_shop',\n",
    "           'action_outdoor_act', 'action_community_interaction', 'action_travel',\n",
    "           'action_meal', 'place_home', 'place_workplace', 'place_outdoor',\n",
    "           'place_other_indoor', 'avg_emotionPositive', 'avg_emotionTension',\n",
    "           'activity_0', 'activity_1', 'activity_2', 'condition_ALONE',\n",
    "            \"('Pre_total_sleep_time',)\", \"('Pre_time_in_bed',)\", \"('Pre_waso',)\", \"('Pre_aal',)\", \"('Pre_movement_index',)\", \"('Pre_fragmentation_index',)\", \"('Pre_sleep_frag_index',)\",\n",
    "           'condition_NOT_ALONE', 'bmi', \"('Pre_wakeupcount',)\", \"('Pre_wakeupduration',)\", \"('Pre_lightsleepduration',)\",\n",
    "            \"('Pre_deepsleepduration',)\", \"('Pre_durationtosleep',)\", \"('Pre_remsleepduration',)\", \"('Pre_durationtowakeup',)\",\n",
    "            \"('Pre_hr_average',)\", \"('Pre_hr_min',)\", \"('Pre_hr_max',)\", \"('Pre_rr_average',)\", \"('Pre_rr_min',)\",\n",
    "            \"('Pre_rr_max',)\", \"('Pre_breathing_disturbances_intensity',)\", \"('Pre_snoring',)\", \"('Pre_snoringepisodecount',)\"]\n",
    "    \n",
    "    test_total_imputed.reset_index(inplace=True, drop=True)\n",
    "    test_2018 = test_total_imputed[year =='2018']\n",
    "    test_2019 = test_total_imputed[year =='2019']\n",
    "    test_2020 = test_total_imputed[year =='2020']\n",
    "    \n",
    "    # 2018\n",
    "    # target마다 학습과 평가를 실시합니다.\n",
    "    tmp_result = [x, 2018]\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var]\n",
    "\n",
    "        X_2018_test = test_2018.drop(target, axis=1)\n",
    "        y_2018_test = test_2018[target_var]\n",
    "\n",
    "        # 정규화 과정을 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std\n",
    "        X_2018_test[numeric_cols] = (X_2018_test[numeric_cols] - train_mean) / train_std\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr.predict(X_2018_test)\n",
    "        accuracy = accuracy_score(y_2018_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "            \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    # 2019\n",
    "    # target마다 학습과 평가를 실시합니다.\n",
    "    tmp_result = [x, 2019]\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var]\n",
    "        \n",
    "        X_2019_test = test_2019.drop(target, axis=1)\n",
    "        y_2019_test = test_2019[target_var]\n",
    "\n",
    "        # 정규화 과정을 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std\n",
    "        X_2019_test[numeric_cols] = (X_2019_test[numeric_cols] - train_mean) / train_std        \n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr.predict(X_2019_test)\n",
    "        accuracy = accuracy_score(y_2019_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "            \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    # 2020\n",
    "    # target마다 학습과 평가를 실시합니다.\n",
    "    tmp_result = [x, 2020]\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var]\n",
    "        \n",
    "        X_2020_test = test_2020.drop(target, axis=1)\n",
    "        y_2020_test = test_2020[target_var]\n",
    "\n",
    "        # 정규화 과정을 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std       \n",
    "        X_2020_test[numeric_cols] = (X_2020_test[numeric_cols] - train_mean) / train_std\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr.predict(X_2020_test)\n",
    "        accuracy = accuracy_score(y_2020_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "            \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44d45e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 파데이터 프레임을 초기화합니다.\n",
    "result_df = pd.DataFrame(columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5d10170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300개의 시드에 대해 테스트합니다.\n",
    "for i in range(300):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e39c62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018년도 데이터\n",
      "Post_sleep 평균: 55.45, 표준편차: 9.30\n",
      "Post_sleepProblem 평균: 60.65, 표준편차: 7.70\n",
      "Post_dream 평균: 67.65, 표준편차: 10.12\n",
      "Post_amCondition 평균: 48.17, 표준편차: 9.33\n",
      "Post_amEmotion 평균: 54.54, 표준편차: 8.86\n",
      "\n",
      "2019년도 데이터\n",
      "Post_sleep 평균: 39.59, 표준편차: 8.69\n",
      "Post_sleepProblem 평균: 58.97, 표준편차: 8.94\n",
      "Post_dream 평균: 64.47, 표준편차: 10.32\n",
      "Post_amCondition 평균: 50.30, 표준편차: 9.41\n",
      "Post_amEmotion 평균: 44.65, 표준편차: 8.09\n",
      "\n",
      "2020년도 데이터\n",
      "Post_sleep 평균: 43.05, 표준편차: 5.92\n",
      "Post_sleepProblem 평균: 52.61, 표준편차: 5.67\n",
      "Post_dream 평균: 60.14, 표준편차: 6.90\n",
      "Post_amCondition 평균: 43.13, 표준편차: 6.50\n",
      "Post_amEmotion 평균: 46.00, 표준편차: 6.82\n"
     ]
    }
   ],
   "source": [
    "# 각 년도에 대한 변수의 평균과 분산 계산\n",
    "df_2018 = result_df[result_df['year'] == 2018]\n",
    "df_2019 = result_df[result_df['year'] == 2019]\n",
    "df_2020 = result_df[result_df['year'] == 2020]\n",
    "\n",
    "variables = ['Post_sleep', 'Post_sleepProblem', 'Post_dream', 'Post_amCondition', 'Post_amEmotion']\n",
    "for df in [df_2018, df_2019, df_2020]:\n",
    "    year = df['year'].values[0]\n",
    "    print(f\"\\n{year}년도 데이터\")\n",
    "    for var in variables:\n",
    "        mean = np.mean(df[var])\n",
    "        variance = math.sqrt(np.var(df[var]))\n",
    "        print(f\"{var} 평균: {mean:.2f}, 표준편차: {variance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab72f33",
   "metadata": {},
   "source": [
    "# 단순통합(최소)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9bb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼들의 교집합을 구하기 위해 df를 복사합니다.\n",
    "total_df_copy = copy.deepcopy(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa687b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = list(set(df2018_imputed.columns) & set(df2019_imputed.columns) & set(df2020_imputed.columns))\n",
    "control.append('userId')\n",
    "control.append('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b889882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    global IterativeImputer\n",
    "    global result_df\n",
    "    \n",
    "    # 데이터 준비\n",
    "    total_df = copy.deepcopy(total_df_copy)\n",
    "    total_df = total_df[control]\n",
    "    user_ids = total_df[\"userId\"].unique()\n",
    "    user_years = total_df.groupby('userId')['year'].first()\n",
    "\n",
    "    train_user_ids, test_user_ids = train_test_split(user_ids, test_size=0.2, random_state=x, stratify=user_years)\n",
    "    train_total = total_df[total_df[\"userId\"].isin(train_user_ids)]\n",
    "    test_total = total_df[total_df[\"userId\"].isin(test_user_ids)]\n",
    "    \n",
    "    train_total.drop(columns=['userId', 'year'], inplace=True)\n",
    "    year = test_total['year'].reset_index(drop=True)\n",
    "    test_total.drop(columns=['userId', 'year'], inplace=True)\n",
    "\n",
    "    # 범주형 변수는 먼저 최빈값으로 결측치를 대체합니다.\n",
    "    for col in category:\n",
    "        try:\n",
    "            train_total[col].fillna(train_total[col].mode()[0], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    for col in category:\n",
    "        try:\n",
    "            test_total[col].fillna(train_total[col].mode()[0], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Mice 모델로 결측치를 대체합니다.\n",
    "    mice_imputer = IterativeImputer()\n",
    "    try:\n",
    "        train_total_imputed = mice_imputer.fit_transform(train_total.values)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    train_total_imputed = pd.DataFrame(train_total_imputed, columns=train_total.columns)\n",
    "    train_total_imputed = train_total_imputed.where(train_total_imputed >= train_total.min(), train_total.min(), axis=1)\n",
    "    train_total_imputed = train_total_imputed.where(train_total_imputed <= train_total.max(), train_total.max(), axis=1)\n",
    "\n",
    "    try:\n",
    "        test_total_imputed = mice_imputer.transform(test_total.values)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    test_total_imputed = pd.DataFrame(test_total_imputed, columns=test_total.columns)\n",
    "    test_total_imputed = test_total_imputed.where(test_total_imputed >= train_total.min(), train_total.min(), axis=1)\n",
    "    test_total_imputed = test_total_imputed.where(test_total_imputed <= train_total.max(), train_total.max(), axis=1)\n",
    "    \n",
    "    # target과 numeric_cols를 구분하여 사용 피처를 확정합니다.\n",
    "    target = [\"('Post_sleep',)\", \"('Post_sleepProblem',)\", \"('Post_dream',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]\n",
    "    numeric_cols_tmp = ['action_personal_care', 'avg_emotionTension'\n",
    "                     'action_sleep', 'place_other_indoor', 'action_recreation_media', 'place_outdoor',\n",
    "                     'action_meal', 'place_workplace', 'action_community_interaction', 'activity_0',\n",
    "                     'condition_NOT_ALONE', 'condition_ALONE', 'action_travel', 'avg_emotionPositive', 'activity_2',\n",
    "                     'place_home', 'action_study', 'age', 'action_household', 'action_outdoor_act', 'action_work', 'activity_1']\n",
    "    numeric_cols = []\n",
    "    for cols_tmp in numeric_cols_tmp:\n",
    "        if cols_tmp in control: numeric_cols.append(cols_tmp)\n",
    "        \n",
    "    test_total_imputed.reset_index(inplace=True, drop=True)\n",
    "    test_2018 = test_total_imputed[year =='2018']\n",
    "    test_2019 = test_total_imputed[year =='2019']\n",
    "    test_2020 = test_total_imputed[year =='2020']\n",
    "    \n",
    "    # 2018\n",
    "    # target마다 학습과 평가를 실시합니다.\n",
    "    tmp_result = [x, 2018]\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var]\n",
    "\n",
    "        X_2018_test = test_2018.drop(target, axis=1)\n",
    "        y_2018_test = test_2018[target_var]\n",
    "\n",
    "        # 정규화 과정을 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std\n",
    "        X_2018_test[numeric_cols] = (X_2018_test[numeric_cols] - train_mean) / train_std\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr.predict(X_2018_test)\n",
    "        accuracy = accuracy_score(y_2018_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "            \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    # 2019\n",
    "    # target마다 학습과 평가를 실시합니다.\n",
    "    tmp_result = [x, 2019]\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var]\n",
    "        \n",
    "        X_2019_test = test_2019.drop(target, axis=1)\n",
    "        y_2019_test = test_2019[target_var]\n",
    "\n",
    "        # 정규화 과정을 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std\n",
    "        X_2019_test[numeric_cols] = (X_2019_test[numeric_cols] - train_mean) / train_std        \n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr.predict(X_2019_test)\n",
    "        accuracy = accuracy_score(y_2019_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "            \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    # 2020\n",
    "    # target마다 학습과 평가를 실시합니다.\n",
    "    tmp_result = [x, 2020]\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var]\n",
    "        \n",
    "        X_2020_test = test_2020.drop(target, axis=1)\n",
    "        y_2020_test = test_2020[target_var]\n",
    "\n",
    "        # 정규화 과정을 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std       \n",
    "        X_2020_test[numeric_cols] = (X_2020_test[numeric_cols] - train_mean) / train_std\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr.predict(X_2020_test)\n",
    "        accuracy = accuracy_score(y_2020_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "            \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a88a4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 파데이터 프레임을 초기화합니다.\n",
    "result_df = pd.DataFrame(columns=[\"seed\", \"year\", \"Post_sleep\", \"Post_sleepProblem\", \"Post_dream\", \"Post_amCondition\", \"Post_amEmotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e54ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300개의 시드에 대해 테스트합니다.\n",
    "for i in range(300):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15d2328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018년도 데이터\n",
      "Post_sleep 평균: 56.37, 표준편차: 10.45\n",
      "Post_sleepProblem 평균: 59.67, 표준편차: 7.64\n",
      "Post_dream 평균: 67.71, 표준편차: 10.15\n",
      "Post_amCondition 평균: 51.39, 표준편차: 10.32\n",
      "Post_amEmotion 평균: 56.58, 표준편차: 9.14\n",
      "\n",
      "2019년도 데이터\n",
      "Post_sleep 평균: 40.33, 표준편차: 7.98\n",
      "Post_sleepProblem 평균: 60.70, 표준편차: 8.28\n",
      "Post_dream 평균: 68.21, 표준편차: 9.44\n",
      "Post_amCondition 평균: 47.30, 표준편차: 9.21\n",
      "Post_amEmotion 평균: 44.45, 표준편차: 8.36\n",
      "\n",
      "2020년도 데이터\n",
      "Post_sleep 평균: 44.07, 표준편차: 6.97\n",
      "Post_sleepProblem 평균: 59.59, 표준편차: 4.72\n",
      "Post_dream 평균: 66.09, 표준편차: 6.08\n",
      "Post_amCondition 평균: 41.89, 표준편차: 7.09\n",
      "Post_amEmotion 평균: 46.02, 표준편차: 6.76\n"
     ]
    }
   ],
   "source": [
    "# 각 년도에 대한 변수의 평균과 분산 계산\n",
    "df_2018 = result_df[result_df['year'] == 2018]\n",
    "df_2019 = result_df[result_df['year'] == 2019]\n",
    "df_2020 = result_df[result_df['year'] == 2020]\n",
    "\n",
    "variables = ['Post_sleep', 'Post_sleepProblem', 'Post_dream', 'Post_amCondition', 'Post_amEmotion']\n",
    "for df in [df_2018, df_2019, df_2020]:\n",
    "    year = df['year'].values[0]\n",
    "    print(f\"\\n{year}년도 데이터\")\n",
    "    for var in variables:\n",
    "        mean = np.mean(df[var])\n",
    "        variance = math.sqrt(np.var(df[var]))\n",
    "        print(f\"{var} 평균: {mean:.2f}, 표준편차: {variance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8cb18",
   "metadata": {},
   "source": [
    "# 데이터 통합 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6949bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(x):\n",
    "    stack_train1 = pd.DataFrame(columns=['seed', 'target_var', 'pat_year_2018', 'pat_year_2019', 'pat_year_2020', \"m1_1\", \"m1_2\", \"m1_3\", \"m2_1\", \"m2_2\", \"m2_3\", \"m3_1\", \"m3_2\", \"m3_3\", 'label'])\n",
    "    stack_test1 = pd.DataFrame(columns=['seed', 'target_var', 'pat_year_2018', 'pat_year_2019', 'pat_year_2020', \"m1_1\", \"m1_2\", \"m1_3\", \"m2_1\", \"m2_2\", \"m2_3\", \"m3_1\", \"m3_2\", \"m3_3\", 'label'])\n",
    "\n",
    "    stack_train2 = pd.DataFrame(columns=['seed', 'target_var', 'pat_year_2018', 'pat_year_2019', 'pat_year_2020', \"m1_1\", \"m1_2\", \"m2_1\", \"m2_2\", \"m3_1\", \"m3_2\", 'label'])\n",
    "    stack_test2 = pd.DataFrame(columns=['seed', 'target_var', 'pat_year_2018', 'pat_year_2019', 'pat_year_2020', \"m1_1\", \"m1_2\", \"m2_1\", \"m2_2\", \"m3_1\", \"m3_2\", 'label'])\n",
    "\n",
    "    # 데이터 준비\n",
    "    user_ids = total_df[\"userId\"].unique()\n",
    "    user_years = total_df.groupby('userId')['year'].first()\n",
    "\n",
    "\n",
    "    train_user_ids, test_user_ids = train_test_split(user_ids, test_size=0.2, random_state=x, stratify=user_years)\n",
    "    train_total = total_df[total_df[\"userId\"].isin(train_user_ids)]\n",
    "    test_total = total_df[total_df[\"userId\"].isin(test_user_ids)]\n",
    "\n",
    "    train_pat = train_total[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']].values\n",
    "    train_total.drop(columns=['userId', 'pat_year_2018', 'pat_year_2019', 'pat_year_2020', 'year'], inplace=True)\n",
    "    test_pat = test_total[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']].values\n",
    "    test_total.drop(columns=['userId', 'pat_year_2018', 'pat_year_2019', 'pat_year_2020', 'year'], inplace=True)\n",
    "    \n",
    "    # 범주형 변수는 먼저 최빈값으로 결측치를 대체합니다.\n",
    "    for col in category:\n",
    "        try:\n",
    "            train_total[col].fillna(train_total[col].mode()[0], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    for col in category:\n",
    "        try:\n",
    "            test_total[col].fillna(train_total[col].mode()[0], inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Mice 모델로 결측치를 대체합니다.\n",
    "    mice_imputer = IterativeImputer()\n",
    "    try:\n",
    "        train_total_imputed = mice_imputer.fit_transform(train_total.values)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    train_total_imputed = pd.DataFrame(train_total_imputed, columns=train_total.columns)\n",
    "    train_total_imputed = train_total_imputed.where(train_total_imputed >= train_total.min(), train_total.min(), axis=1)\n",
    "    train_total_imputed = train_total_imputed.where(train_total_imputed <= train_total.max(), train_total.max(), axis=1)\n",
    "    train_total_imputed[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']] = train_pat\n",
    "\n",
    "    try:\n",
    "        test_total_imputed = mice_imputer.transform(test_total.values)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    test_total_imputed = pd.DataFrame(test_total_imputed, columns=test_total.columns)\n",
    "    test_total_imputed = test_total_imputed.where(test_total_imputed >= train_total.min(), train_total.min(), axis=1)\n",
    "    test_total_imputed = test_total_imputed.where(test_total_imputed <= train_total.max(), train_total.max(), axis=1)\n",
    "    test_total_imputed[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']] = test_pat\n",
    "    \n",
    "    # target과 numeric_cols를 구분하여 사용 피처를 확정합니다.\n",
    "    target = [\"('Post_sleep',)\", \"('Post_sleepProblem',)\", \"('Post_dream',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]\n",
    "    numeric_cols = ['age', 'action_personal_care', 'action_sleep',\n",
    "       'action_work', 'action_study', 'action_household',\n",
    "       'action_recreation_media', 'action_care_housemem', 'action_shop',\n",
    "       'action_outdoor_act', 'action_community_interaction', 'action_travel',\n",
    "       'action_meal', 'place_home', 'place_workplace', 'place_outdoor',\n",
    "       'place_other_indoor', 'avg_emotionPositive', 'avg_emotionTension',\n",
    "       'activity_0', 'activity_1', 'activity_2', 'condition_ALONE',\n",
    "        \"('Pre_total_sleep_time',)\", \"('Pre_time_in_bed',)\", \"('Pre_waso',)\", \"('Pre_aal',)\", \"('Pre_movement_index',)\", \"('Pre_fragmentation_index',)\", \"('Pre_sleep_frag_index',)\",\n",
    "       'condition_NOT_ALONE', 'bmi', \"('Pre_wakeupcount',)\", \"('Pre_wakeupduration',)\", \"('Pre_lightsleepduration',)\",\n",
    "        \"('Pre_deepsleepduration',)\", \"('Pre_durationtosleep',)\", \"('Pre_remsleepduration',)\", \"('Pre_durationtowakeup',)\",\n",
    "        \"('Pre_hr_average',)\", \"('Pre_hr_min',)\", \"('Pre_hr_max',)\", \"('Pre_rr_average',)\", \"('Pre_rr_min',)\",\n",
    "        \"('Pre_rr_max',)\", \"('Pre_breathing_disturbances_intensity',)\", \"('Pre_snoring',)\", \"('Pre_snoringepisodecount',)\"]\n",
    "    \n",
    "    # target 변수에 대해 각각 lr 모델을 학습시키고 stack을 쌓습니다.\n",
    "    for target_var in target:\n",
    "        X_train = train_total_imputed.drop(target, axis=1)\n",
    "        y_train = train_total_imputed[target_var].values\n",
    "        \n",
    "        X_train_2018 = train_total_imputed[train_total_imputed['pat_year_2018']==1].drop(target, axis=1)\n",
    "        train_mean = X_train_2018[numeric_cols].mean()\n",
    "        train_std = X_train_2018[numeric_cols].std() + 0.000001\n",
    "        X_train_2018[numeric_cols] = (X_train_2018[numeric_cols] - train_mean) / train_std\n",
    "        y_train_2018 = train_total_imputed[train_total_imputed['pat_year_2018']==1][target_var].values\n",
    "        \n",
    "        X_train_2019 = train_total_imputed[train_total_imputed['pat_year_2019']==1].drop(target, axis=1)\n",
    "        train_mean = X_train_2019[numeric_cols].mean()\n",
    "        train_std = X_train_2019[numeric_cols].std() + 0.000001\n",
    "        X_train_2019[numeric_cols] = (X_train_2019[numeric_cols] - train_mean) / train_std\n",
    "        y_train_2019 = train_total_imputed[train_total_imputed['pat_year_2019']==1][target_var].values\n",
    "        \n",
    "        X_train_2020 = train_total_imputed[train_total_imputed['pat_year_2020']==1].drop(target, axis=1)\n",
    "        train_mean = X_train_2020[numeric_cols].mean()\n",
    "        train_std = X_train_2020[numeric_cols].std() + 0.000001\n",
    "        X_train_2020[numeric_cols] = (X_train_2020[numeric_cols] - train_mean) / train_std\n",
    "        y_train_2020 = train_total_imputed[train_total_imputed['pat_year_2020']==1][target_var].values\n",
    "        \n",
    "        X_test = test_total_imputed.drop(target, axis=1)\n",
    "        y_test = test_total_imputed[target_var].values\n",
    "\n",
    "        # 데이터 정규화를 진행합니다.\n",
    "        train_mean = X_train[numeric_cols].mean()\n",
    "        train_std = X_train[numeric_cols].std() + 0.000001\n",
    "\n",
    "        X_train[numeric_cols] = (X_train[numeric_cols] - train_mean) / train_std\n",
    "        X_test[numeric_cols] = (X_test[numeric_cols] - train_mean) / train_std\n",
    "        \n",
    "        # 예측이 3개로 이루어지는 경우와 2개로 나누어지는 경우를 나눕니다\n",
    "        if target_var in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "            lr1 = LogisticRegression()\n",
    "            lr1.fit(X_train_2018, y_train_2018)\n",
    "            \n",
    "            lr4 = LogisticRegression()\n",
    "            lr4.fit(X_train_2019, y_train_2019) \n",
    "            \n",
    "            lr7 = LogisticRegression()\n",
    "            lr7.fit(X_train_2020, y_train_2020)   \n",
    "            \n",
    "            X_train_stack1 = lr1.predict_proba(X_train[lr1.feature_names_in_.tolist()])\n",
    "            X_train_stack2 = lr4.predict_proba(X_train[lr4.feature_names_in_.tolist()])\n",
    "            X_train_stack3 = lr7.predict_proba(X_train[lr7.feature_names_in_.tolist()])\n",
    "            \n",
    "            X_test_stack1 = lr1.predict_proba(X_test[lr1.feature_names_in_.tolist()])\n",
    "            X_test_stack2 = lr4.predict_proba(X_test[lr4.feature_names_in_.tolist()])\n",
    "            X_test_stack3 = lr7.predict_proba(X_test[lr7.feature_names_in_.tolist()])\n",
    "            \n",
    "            X_train_stack_tmp = np.concatenate(([[x, target_var]] * len(X_train_stack1), train_total_imputed[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']].reset_index(drop=True), X_train_stack1, X_train_stack2, X_train_stack3, y_train.reshape(len(X_train_stack1), -1)), axis=1)\n",
    "            X_train_stack_tmp = pd.DataFrame(X_train_stack_tmp, columns=stack_train1.columns)\n",
    "            stack_train1 = pd.concat([stack_train1, X_train_stack_tmp], axis=0, ignore_index = True)\n",
    "             \n",
    "            X_test_stack_tmp = np.concatenate(([[x, target_var]] * len(X_test_stack1), test_total_imputed[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']].reset_index(drop=True), X_test_stack1, X_test_stack2, X_test_stack3, y_test.reshape(len(X_test_stack1), -1)), axis=1)\n",
    "            X_test_stack_tmp = pd.DataFrame(X_test_stack_tmp, columns=stack_test1.columns)\n",
    "            stack_test1 = pd.concat([stack_test1, X_test_stack_tmp], axis=0, ignore_index = True)\n",
    "            \n",
    "        elif target_var in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "            lr2 = LogisticRegression()\n",
    "            lr2.fit(X_train_2018, y_train_2018)\n",
    "            \n",
    "            lr5 = LogisticRegression()\n",
    "            lr5.fit(X_train_2019, y_train_2019) \n",
    "            \n",
    "            lr8 = LogisticRegression()\n",
    "            lr8.fit(X_train_2020, y_train_2020)       \n",
    "        \n",
    "            X_train_stack1 = lr2.predict_proba(X_train[lr2.feature_names_in_.tolist()])\n",
    "            X_train_stack2 = lr5.predict_proba(X_train[lr5.feature_names_in_.tolist()])\n",
    "            X_train_stack3 = lr8.predict_proba(X_train[lr8.feature_names_in_.tolist()])\n",
    "\n",
    "            X_test_stack1 = lr2.predict_proba(X_test[lr2.feature_names_in_.tolist()])\n",
    "            X_test_stack2 = lr5.predict_proba(X_test[lr5.feature_names_in_.tolist()])\n",
    "            X_test_stack3 = lr8.predict_proba(X_test[lr8.feature_names_in_.tolist()])\n",
    "            \n",
    "            X_train_stack_tmp = np.concatenate(([[x, target_var]] * len(X_train_stack1), train_total_imputed[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']].reset_index(drop=True), X_train_stack1, X_train_stack2, X_train_stack3, y_train.reshape(len(X_train_stack1), -1)), axis=1)\n",
    "            X_train_stack_tmp = pd.DataFrame(X_train_stack_tmp, columns=stack_train2.columns)\n",
    "            stack_train2 = pd.concat([stack_train2, X_train_stack_tmp], axis=0, ignore_index = True)\n",
    "                \n",
    "            X_test_stack_tmp = np.concatenate(([[x, target_var]] * len(X_test_stack1), test_total_imputed[['pat_year_2018', 'pat_year_2019', 'pat_year_2020']].reset_index(drop=True), X_test_stack1, X_test_stack2, X_test_stack3, y_test.reshape(len(X_test_stack1), -1)), axis=1)\n",
    "            X_test_stack_tmp = pd.DataFrame(X_test_stack_tmp, columns=stack_test2.columns)\n",
    "            stack_test2 = pd.concat([stack_test2, X_test_stack_tmp], axis=0, ignore_index = True)\n",
    "        \n",
    "    return stack_train1, stack_test1, stack_train2, stack_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c649ab4",
   "metadata": {},
   "source": [
    "# 데이터 통합1: 보팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2144a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    global result_df\n",
    "\n",
    "    try:\n",
    "        stack_train1, stack_test1, stack_train2, stack_test2 = stack(x)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    \n",
    "    tmp2018_1 = stack_test1[stack_test1['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_1 = stack_test1[stack_test1['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_1 = stack_test1[stack_test1['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp2018_2 = stack_test2[stack_test2['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_2 = stack_test2[stack_test2['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_2 = stack_test2[stack_test2['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp_result = [x, 2018]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2018_1_tmp = tmp2018_1[tmp2018_1['target_var']==col].reset_index(drop=True)\n",
    "\n",
    "        df1 = tmp2018_1_tmp.iloc[:,[5, 8, 11]].astype(float).mean(axis=1)\n",
    "        df2 = tmp2018_1_tmp.iloc[:,[6, 9, 12]].astype(float).mean(axis=1)\n",
    "        df3 = tmp2018_1_tmp.iloc[:,[7, 10, 13]].astype(float).mean(axis=1)\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = (df1 > df2) & (df1 > df3)\n",
    "        result[1] = (df2 > df1) & (df2 > df3)\n",
    "        result[2] = (df3 > df1) & (df3 > df2)\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(tmp2018_1_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2018_2_tmp = tmp2018_2[tmp2018_2['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        df1 = tmp2018_2_tmp.iloc[:,[5, 7, 9]].astype(float).mean(axis=1)\n",
    "        df2 = tmp2018_2_tmp.iloc[:,[6, 8, 10]].astype(float).mean(axis=1)\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = df1 > df2\n",
    "        result[1] = df2 > df1\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "        accuracy = accuracy_score(tmp2018_2_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "    \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    tmp_result = [x, 2019]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2019_1_tmp = tmp2019_1[tmp2019_1['target_var']==col].reset_index(drop=True)\n",
    "\n",
    "        df1 = tmp2019_1_tmp.iloc[:,[5, 8, 11]].astype(float).mean(axis=1)\n",
    "        df2 = tmp2019_1_tmp.iloc[:,[6, 9, 12]].astype(float).mean(axis=1)\n",
    "        df3 = tmp2019_1_tmp.iloc[:,[7, 10, 13]].astype(float).mean(axis=1)\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = (df1 > df2) & (df1 > df3)\n",
    "        result[1] = (df2 > df1) & (df2 > df3)\n",
    "        result[2] = (df3 > df1) & (df3 > df2)\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(tmp2019_1_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2019_2_tmp = tmp2019_2[tmp2019_2['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        df1 = tmp2019_2_tmp.iloc[:,[5, 7, 9]].astype(float).mean(axis=1)\n",
    "        df2 = tmp2019_2_tmp.iloc[:,[6, 8, 10]].astype(float).mean(axis=1)\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = df1 > df2\n",
    "        result[1] = df2 > df1\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "        accuracy = accuracy_score(tmp2019_2_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "    \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    tmp_result = [x, 2020]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2020_1_tmp = tmp2020_1[tmp2020_1['target_var']==col].reset_index(drop=True)\n",
    "\n",
    "        df1 = tmp2020_1_tmp.iloc[:,[5, 8, 11]].astype(float).mean(axis=1)\n",
    "        df2 = tmp2020_1_tmp.iloc[:,[6, 9, 12]].astype(float).mean(axis=1)\n",
    "        df3 = tmp2020_1_tmp.iloc[:,[7, 10, 13]].astype(float).mean(axis=1)\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = (df1 > df2) & (df1 > df3)\n",
    "        result[1] = (df2 > df1) & (df2 > df3)\n",
    "        result[2] = (df3 > df1) & (df3 > df2)\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(tmp2020_1_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2020_2_tmp = tmp2020_2[tmp2020_2['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        df1 = tmp2020_2_tmp.iloc[:,[5, 7, 9]].astype(float).mean(axis=1)\n",
    "        df2 = tmp2020_2_tmp.iloc[:,[6, 8, 10]].astype(float).mean(axis=1)\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = df1 > df2\n",
    "        result[1] = df2 > df1\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "        accuracy = accuracy_score(tmp2020_2_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "    \n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de66fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 파데이터 프레임을 초기화합니다.\n",
    "result_df = pd.DataFrame(columns= ['seed', 'year', 'Post_sleep', 'Post_amCondition', 'Post_amEmotion', 'Post_sleepProblem', 'Post_dream'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c631adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101에서 오류가 발생했습니다.\n",
      "101에서 오류가 발생했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 300개의 시드에 대해 테스트합니다.\n",
    "for i in range(300):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec8abb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018년도 데이터\n",
      "Post_sleep 평균: 50.90, 표준편차: 8.76\n",
      "Post_sleepProblem 평균: 61.69, 표준편차: 8.47\n",
      "Post_dream 평균: 66.15, 표준편차: 10.22\n",
      "Post_amCondition 평균: 44.65, 표준편차: 8.48\n",
      "Post_amEmotion 평균: 51.67, 표준편차: 9.54\n",
      "\n",
      "2019년도 데이터\n",
      "Post_sleep 평균: 40.42, 표준편차: 8.59\n",
      "Post_sleepProblem 평균: 57.49, 표준편차: 9.08\n",
      "Post_dream 평균: 66.45, 표준편차: 10.23\n",
      "Post_amCondition 평균: 49.30, 표준편차: 10.44\n",
      "Post_amEmotion 평균: 41.66, 표준편차: 8.93\n",
      "\n",
      "2020년도 데이터\n",
      "Post_sleep 평균: 40.08, 표준편차: 6.33\n",
      "Post_sleepProblem 평균: 52.55, 표준편차: 5.77\n",
      "Post_dream 평균: 57.83, 표준편차: 8.15\n",
      "Post_amCondition 평균: 40.53, 표준편차: 7.03\n",
      "Post_amEmotion 평균: 41.27, 표준편차: 6.35\n"
     ]
    }
   ],
   "source": [
    "# 각 년도에 대한 변수의 평균과 분산 계산\n",
    "df_2018 = result_df[result_df['year'] == 2018]\n",
    "df_2019 = result_df[result_df['year'] == 2019]\n",
    "df_2020 = result_df[result_df['year'] == 2020]\n",
    "\n",
    "variables = ['Post_sleep', 'Post_sleepProblem', 'Post_dream', 'Post_amCondition', 'Post_amEmotion']\n",
    "for df in [df_2018, df_2019, df_2020]:\n",
    "    year = df['year'].values[0]\n",
    "    print(f\"\\n{year}년도 데이터\")\n",
    "    for var in variables:\n",
    "        mean = np.mean(df[var])\n",
    "        variance = math.sqrt(np.var(df[var]))\n",
    "        print(f\"{var} 평균: {mean:.2f}, 표준편차: {variance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d71e49",
   "metadata": {},
   "source": [
    "# 데이터 통합2: 가중치 보팅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794ead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, m1, m2, m3):\n",
    "    global result_df\n",
    "    \n",
    "    try:\n",
    "        stack_train1, stack_test1, stack_train2, stack_test2 = stack(x)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    \n",
    "    tmp2018_1 = stack_test1[stack_test1['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_1 = stack_test1[stack_test1['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_1 = stack_test1[stack_test1['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp2018_2 = stack_test2[stack_test2['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_2 = stack_test2[stack_test2['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_2 = stack_test2[stack_test2['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp_result = [x, 2018]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2018_1_tmp = tmp2018_1[tmp2018_1['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        tmp2018_1_tmp[['m1_1', 'm1_2', 'm1_3', 'm2_1', 'm2_2', 'm2_3', 'm3_1', 'm3_2', 'm3_3']] = tmp2018_1_tmp[['m1_1', 'm1_2', 'm1_3', 'm2_1', 'm2_2', 'm2_3', 'm3_1', 'm3_2', 'm3_3']].astype('float')\n",
    "        tmp2018_1_tmp[['m1_1', 'm1_2', 'm1_3']] *= m1\n",
    "        \n",
    "        df1 = (tmp2018_1_tmp['m1_1'] + tmp2018_1_tmp['m2_1'] + tmp2018_1_tmp['m3_1']) / 3\n",
    "        df2 = (tmp2018_1_tmp['m1_2'] + tmp2018_1_tmp['m2_2'] + tmp2018_1_tmp['m3_2']) / 3\n",
    "        df3 = (tmp2018_1_tmp['m1_3'] + tmp2018_1_tmp['m2_3'] + tmp2018_1_tmp['m3_3']) / 3\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = (df1 > df2) & (df1 > df3)\n",
    "        result[1] = (df2 > df1) & (df2 > df3)\n",
    "        result[2] = (df3 > df1) & (df3 > df2)\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(tmp2018_1_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2018_2_tmp = tmp2018_2[tmp2018_2['target_var']==col].reset_index(drop=True)\n",
    "\n",
    "        tmp2018_2_tmp[['m1_1', 'm1_2', 'm2_1', 'm2_2', 'm3_1', 'm3_2']] = tmp2018_2_tmp[['m1_1', 'm1_2', 'm2_1', 'm2_2', 'm3_1', 'm3_2']].astype('float')\n",
    "        tmp2018_2_tmp[['m1_1', 'm1_2']] *= m1\n",
    "        \n",
    "        df1 = (tmp2018_2_tmp['m1_1'] + tmp2018_2_tmp['m2_1'] +tmp2018_2_tmp['m3_1']) / 3\n",
    "        df2 = (tmp2018_2_tmp['m1_2'] + tmp2018_2_tmp['m2_2'] +tmp2018_2_tmp['m3_2']) / 3\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = df1 > df2\n",
    "        result[1] = df2 > df1\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "        accuracy = accuracy_score(tmp2018_2_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    tmp_result = [x, 2019]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2019_1_tmp = tmp2019_1[tmp2019_1['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        tmp2019_1_tmp[['m1_1', 'm1_2', 'm1_3', 'm2_1', 'm2_2', 'm2_3', 'm3_1', 'm3_2', 'm3_3']] = tmp2019_1_tmp[['m1_1', 'm1_2', 'm1_3', 'm2_1', 'm2_2', 'm2_3', 'm3_1', 'm3_2', 'm3_3']].astype('float')\n",
    "        tmp2019_1_tmp[['m2_1', 'm2_2', 'm2_3']] *= m2\n",
    "        \n",
    "        df1 = (tmp2019_1_tmp['m1_1'] + tmp2019_1_tmp['m2_1'] + tmp2019_1_tmp['m3_1']) / 3\n",
    "        df2 = (tmp2019_1_tmp['m1_2'] + tmp2019_1_tmp['m2_2'] + tmp2019_1_tmp['m3_2']) / 3\n",
    "        df3 = (tmp2019_1_tmp['m1_3'] + tmp2019_1_tmp['m2_3'] + tmp2019_1_tmp['m3_3']) / 3\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = (df1 > df2) & (df1 > df3)\n",
    "        result[1] = (df2 > df1) & (df2 > df3)\n",
    "        result[2] = (df3 > df1) & (df3 > df2)\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(tmp2019_1_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2019_2_tmp = tmp2019_2[tmp2019_2['target_var']==col].reset_index(drop=True)\n",
    "\n",
    "        tmp2019_2_tmp[['m1_1', 'm1_2', 'm2_1', 'm2_2', 'm3_1', 'm3_2']] = tmp2019_2_tmp[['m1_1', 'm1_2', 'm2_1', 'm2_2', 'm3_1', 'm3_2']].astype('float')\n",
    "        tmp2019_2_tmp[['m2_1', 'm2_2']] *= m2\n",
    "        \n",
    "        df1 = (tmp2019_2_tmp['m1_1'] + tmp2019_2_tmp['m2_1'] +tmp2019_2_tmp['m3_1']) / 3\n",
    "        df2 = (tmp2019_2_tmp['m1_2'] + tmp2019_2_tmp['m2_2'] +tmp2019_2_tmp['m3_2']) / 3\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = df1 > df2\n",
    "        result[1] = df2 > df1\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "        accuracy = accuracy_score(tmp2019_2_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    tmp_result = [x, 2020]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2020_1_tmp = tmp2020_1[tmp2020_1['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        tmp2020_1_tmp[['m1_1', 'm1_2', 'm1_3', 'm2_1', 'm2_2', 'm2_3', 'm3_1', 'm3_2', 'm3_3']] = tmp2020_1_tmp[['m1_1', 'm1_2', 'm1_3', 'm2_1', 'm2_2', 'm2_3', 'm3_1', 'm3_2', 'm3_3']].astype('float')\n",
    "        tmp2020_1_tmp[['m3_1', 'm3_2', 'm2_3']] *= m3\n",
    "        \n",
    "        df1 = (tmp2020_1_tmp['m1_1'] + tmp2020_1_tmp['m2_1'] + tmp2020_1_tmp['m3_1']) / 3\n",
    "        df2 = (tmp2020_1_tmp['m1_2'] + tmp2020_1_tmp['m2_2'] + tmp2020_1_tmp['m3_2']) / 3\n",
    "        df3 = (tmp2020_1_tmp['m1_3'] + tmp2020_1_tmp['m2_3'] + tmp2020_1_tmp['m3_3']) / 3\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = (df1 > df2) & (df1 > df3)\n",
    "        result[1] = (df2 > df1) & (df2 > df3)\n",
    "        result[2] = (df3 > df1) & (df3 > df2)\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(tmp2020_1_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2020_2_tmp = tmp2020_2[tmp2020_2['target_var']==col].reset_index(drop=True)\n",
    "\n",
    "        tmp2020_2_tmp[['m1_1', 'm1_2', 'm2_1', 'm2_2', 'm3_1', 'm3_2']] = tmp2020_2_tmp[['m1_1', 'm1_2', 'm2_1', 'm2_2', 'm3_1', 'm3_2']].astype('float')\n",
    "        tmp2020_2_tmp[['m3_1', 'm3_2']] *= m3\n",
    "        \n",
    "        df1 = (tmp2020_2_tmp['m1_1'] + tmp2020_2_tmp['m2_1'] +tmp2020_2_tmp['m3_1']) / 3\n",
    "        df2 = (tmp2020_2_tmp['m1_2'] + tmp2020_2_tmp['m2_2'] +tmp2020_2_tmp['m3_2']) / 3\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[0] = df1 > df2\n",
    "        result[1] = df2 > df1\n",
    "\n",
    "        result = result.idxmax(axis=1)\n",
    "        accuracy = accuracy_score(tmp2020_2_tmp.iloc[:,-1].astype(float).values, result.astype(float).values)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8874ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 파데이터 프레임을 선언합니다.\n",
    "result_df = pd.DataFrame(columns=['seed', 'year', 'Post_sleep', 'Post_amCondition', 'Post_amEmotion', 'Post_sleepProblem', 'Post_dream'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1338d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101에서 오류가 발생했습니다.\n",
      "101에서 오류가 발생했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 10개의 시드에 대해 테스트합니다.\n",
    "for i in range(300):\n",
    "    test(i, 1.5, 1.5, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1be63865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018년도 데이터\n",
      "Post_sleep 평균: 50.79, 표준편차: 8.83\n",
      "Post_sleepProblem 평균: 62.16, 표준편차: 8.44\n",
      "Post_dream 평균: 66.60, 표준편차: 9.60\n",
      "Post_amCondition 평균: 44.49, 표준편차: 8.45\n",
      "Post_amEmotion 평균: 52.75, 표준편차: 9.83\n",
      "\n",
      "2019년도 데이터\n",
      "Post_sleep 평균: 38.75, 표준편차: 8.55\n",
      "Post_sleepProblem 평균: 56.67, 표준편차: 8.73\n",
      "Post_dream 평균: 67.51, 표준편차: 10.24\n",
      "Post_amCondition 평균: 49.49, 표준편차: 10.29\n",
      "Post_amEmotion 평균: 40.70, 표준편차: 9.06\n",
      "\n",
      "2020년도 데이터\n",
      "Post_sleep 평균: 40.46, 표준편차: 6.41\n",
      "Post_sleepProblem 평균: 53.45, 표준편차: 5.92\n",
      "Post_dream 평균: 59.16, 표준편차: 7.45\n",
      "Post_amCondition 평균: 41.45, 표준편차: 7.21\n",
      "Post_amEmotion 평균: 41.26, 표준편차: 6.25\n"
     ]
    }
   ],
   "source": [
    "# 각 년도에 대한 변수의 평균과 분산 계산\n",
    "df_2018 = result_df[result_df['year'] == 2018]\n",
    "df_2019 = result_df[result_df['year'] == 2019]\n",
    "df_2020 = result_df[result_df['year'] == 2020]\n",
    "\n",
    "variables = ['Post_sleep', 'Post_sleepProblem', 'Post_dream', 'Post_amCondition', 'Post_amEmotion']\n",
    "for df in [df_2018, df_2019, df_2020]:\n",
    "    year = df['year'].values[0]\n",
    "    print(f\"\\n{year}년도 데이터\")\n",
    "    for var in variables:\n",
    "        mean = np.mean(df[var])\n",
    "        variance = math.sqrt(np.var(df[var]))\n",
    "        print(f\"{var} 평균: {mean:.2f}, 표준편차: {variance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876cf83",
   "metadata": {},
   "source": [
    "# 데이터 통합3: 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcbeb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    global result_df\n",
    "        \n",
    "    try:\n",
    "        stack_train1, stack_test1, stack_train2, stack_test2 = stack(x)\n",
    "    except:\n",
    "        print(f'{x}에서 오류가 발생했습니다.')\n",
    "        return\n",
    "    \n",
    "    tmp2018_train_1 = stack_train1[stack_train1['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_train_1 = stack_train1[stack_train1['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_train_1 = stack_train1[stack_train1['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp2018_train_2 = stack_train2[stack_train2['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_train_2 = stack_train2[stack_train2['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_train_2 = stack_train2[stack_train2['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp2018_test_1 = stack_test1[stack_test1['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_test_1 = stack_test1[stack_test1['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_test_1 = stack_test1[stack_test1['pat_year_2020'].astype('int') == 1]\n",
    "    \n",
    "    tmp2018_test_2 = stack_test2[stack_test2['pat_year_2018'].astype('int') == 1]\n",
    "    tmp2019_test_2 = stack_test2[stack_test2['pat_year_2019'].astype('int') == 1]\n",
    "    tmp2020_test_2 = stack_test2[stack_test2['pat_year_2020'].astype('int') == 1]    \n",
    "\n",
    "    \n",
    "    tmp_result = [x, 2018]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2018_train_1_tmp = tmp2018_train_1[tmp2018_train_1['target_var']==col].reset_index(drop=True)\n",
    "        tmp2018_test_1_tmp = tmp2018_test_1[tmp2018_test_1['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        X_train = tmp2018_train_1_tmp.iloc[:,5:-1]\n",
    "        y_train = tmp2018_train_1_tmp.iloc[:,-1]\n",
    "        \n",
    "        X_test = tmp2018_test_1_tmp.iloc[:,5:-1]\n",
    "        y_test = tmp2018_test_1_tmp.iloc[:,-1]\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # early stopping을 적용합니다.\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        # 모델을 사용하여 test 데이터에 대한 예측 결과를 계산합니다.\n",
    "        y_pred = lr.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2018_train_2_tmp = tmp2018_train_2[tmp2018_train_2['target_var']==col].reset_index(drop=True)\n",
    "        tmp2018_test_2_tmp = tmp2018_test_2[tmp2018_test_2['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        X_train = tmp2018_train_2_tmp.iloc[:,5:-1]\n",
    "        y_train = tmp2018_train_2_tmp.iloc[:,-1]\n",
    "        \n",
    "        X_test = tmp2018_test_2_tmp.iloc[:,5:-1]\n",
    "        y_test = tmp2018_test_2_tmp.iloc[:,-1]\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # early stopping을 적용합니다.\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        # 모델을 사용하여 test 데이터에 대한 예측 결과를 계산합니다.\n",
    "        y_pred = lr.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "\n",
    "    tmp_result = [x, 2019]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2019_train_1_tmp = tmp2019_train_1[tmp2019_train_1['target_var']==col].reset_index(drop=True)\n",
    "        tmp2019_test_1_tmp = tmp2019_test_1[tmp2019_test_1['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        X_train = tmp2019_train_1_tmp.iloc[:,5:-1]\n",
    "        y_train = tmp2019_train_1_tmp.iloc[:,-1]\n",
    "        \n",
    "        X_test = tmp2019_test_1_tmp.iloc[:,5:-1]\n",
    "        y_test = tmp2019_test_1_tmp.iloc[:,-1]\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # early stopping을 적용합니다.\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        # 모델을 사용하여 test 데이터에 대한 예측 결과를 계산합니다.\n",
    "        y_pred = lr.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2019_train_2_tmp = tmp2019_train_2[tmp2019_train_2['target_var']==col].reset_index(drop=True)\n",
    "        tmp2019_test_2_tmp = tmp2019_test_2[tmp2019_test_2['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        X_train = tmp2019_train_2_tmp.iloc[:,5:-1]\n",
    "        y_train = tmp2019_train_2_tmp.iloc[:,-1]\n",
    "        \n",
    "        X_test = tmp2019_test_2_tmp.iloc[:,5:-1]\n",
    "        y_test = tmp2019_test_2_tmp.iloc[:,-1]\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # early stopping을 적용합니다.\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        # 모델을 사용하여 test 데이터에 대한 예측 결과를 계산합니다.\n",
    "        y_pred = lr.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)\n",
    "    \n",
    "    tmp_result = [x, 2020]\n",
    "    for col in [\"('Post_sleep',)\", \"('Post_amCondition',)\", \"('Post_amEmotion',)\"]:\n",
    "        tmp2020_train_1_tmp = tmp2020_train_1[tmp2020_train_1['target_var']==col].reset_index(drop=True)\n",
    "        tmp2020_test_1_tmp = tmp2020_test_1[tmp2020_test_1['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        X_train = tmp2020_train_1_tmp.iloc[:,5:-1]\n",
    "        y_train = tmp2020_train_1_tmp.iloc[:,-1]\n",
    "        \n",
    "        X_test = tmp2020_test_1_tmp.iloc[:,5:-1]\n",
    "        y_test = tmp2020_test_1_tmp.iloc[:,-1]\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # early stopping을 적용합니다.\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        # 모델을 사용하여 test 데이터에 대한 예측 결과를 계산합니다.\n",
    "        y_pred = lr.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "    for col in [\"('Post_sleepProblem',)\", \"('Post_dream',)\"]:\n",
    "        tmp2020_train_2_tmp = tmp2020_train_2[tmp2020_train_2['target_var']==col].reset_index(drop=True)\n",
    "        tmp2020_test_2_tmp = tmp2020_test_2[tmp2020_test_2['target_var']==col].reset_index(drop=True)\n",
    "        \n",
    "        X_train = tmp2020_train_2_tmp.iloc[:,5:-1]\n",
    "        y_train = tmp2020_train_2_tmp.iloc[:,-1]\n",
    "        \n",
    "        X_test = tmp2020_test_2_tmp.iloc[:,5:-1]\n",
    "        y_test = tmp2020_test_2_tmp.iloc[:,-1]\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # early stopping을 적용합니다.\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        # 모델을 사용하여 test 데이터에 대한 예측 결과를 계산합니다.\n",
    "        y_pred = lr.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tmp_result.append(round(accuracy * 100, 0))\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame([tmp_result], columns=result_df.columns)\n",
    "    result_df = pd.concat([result_df, tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b91dc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 파데이터 프레임을 선언합니다.\n",
    "result_df = pd.DataFrame(columns=['seed', 'year', 'Post_sleep', 'Post_amCondition', 'Post_amEmotion', 'Post_sleepProblem', 'Post_dream'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4eeb626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101에서 오류가 발생했습니다.\n",
      "101에서 오류가 발생했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 10개의 시드에 대해 테스트합니다.\n",
    "for i in range(300):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3aaabe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018년도 데이터\n",
      "Post_sleep 평균: 50.60, 표준편차: 9.52\n",
      "Post_sleepProblem 평균: 60.27, 표준편차: 8.11\n",
      "Post_dream 평균: 67.02, 표준편차: 8.03\n",
      "Post_amCondition 평균: 41.83, 표준편차: 8.23\n",
      "Post_amEmotion 평균: 49.42, 표준편차: 9.42\n",
      "\n",
      "2019년도 데이터\n",
      "Post_sleep 평균: 35.09, 표준편차: 7.42\n",
      "Post_sleepProblem 평균: 54.99, 표준편차: 7.85\n",
      "Post_dream 평균: 67.73, 표준편차: 9.81\n",
      "Post_amCondition 평균: 47.30, 표준편차: 8.45\n",
      "Post_amEmotion 평균: 38.04, 표준편차: 8.47\n",
      "\n",
      "2020년도 데이터\n",
      "Post_sleep 평균: 42.89, 표준편차: 6.56\n",
      "Post_sleepProblem 평균: 52.11, 표준편차: 6.86\n",
      "Post_dream 평균: 58.44, 표준편차: 7.20\n",
      "Post_amCondition 평균: 41.38, 표준편차: 6.34\n",
      "Post_amEmotion 평균: 41.62, 표준편차: 6.94\n"
     ]
    }
   ],
   "source": [
    "# 각 년도에 대한 변수의 평균과 분산 계산\n",
    "df_2018 = result_df[result_df['year'] == 2018]\n",
    "df_2019 = result_df[result_df['year'] == 2019]\n",
    "df_2020 = result_df[result_df['year'] == 2020]\n",
    "\n",
    "variables = ['Post_sleep', 'Post_sleepProblem', 'Post_dream', 'Post_amCondition', 'Post_amEmotion']\n",
    "for df in [df_2018, df_2019, df_2020]:\n",
    "    year = df['year'].values[0]\n",
    "    print(f\"\\n{year}년도 데이터\")\n",
    "    for var in variables:\n",
    "        mean = np.mean(df[var])\n",
    "        variance = math.sqrt(np.var(df[var]))\n",
    "        print(f\"{var} 평균: {mean:.2f}, 표준편차: {variance:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa241227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow gpu 2.7.0",
   "language": "python",
   "name": "tensorflow_2_7_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
